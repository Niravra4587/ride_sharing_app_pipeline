# ğŸš• Ride-Sharing Analytics Pipeline

A simplified ride-sharing analytics pipeline built using Python to simulate both **batch** and **streaming** data ingestion and processing. This project uses realistic mock data to compute insights like hourly trends and rolling metrics.

---
## ER Diagram
<img width="1169" height="668" alt="image" src="https://github.com/user-attachments/assets/8a180962-94fc-417e-a3ee-249d047d1e3a" />

## Architecture Diagram
<img width="644" height="488" alt="architecture_diagram drawio" src="https://github.com/user-attachments/assets/b2cae660-2158-445e-ae02-a0399a45f756" />

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ inputs/
â”‚   â”œâ”€â”€ rides.csv               # Batch data (mock ride events)
â”‚   â”œâ”€â”€ hourly_csv.log          # Output of hourly analytics from querying
â”‚   â””â”€â”€ rides.jsonl             # Live-streamed rides (one record per line)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ batch_data_generator.py     # Generate rides.csv
â”‚   â”œâ”€â”€ live_data_gen.py            # Simulate live ride stream to JSONL
â”‚   â”œâ”€â”€ etl_batch.py                # ETL: clean and load batch data to SQLite
â”‚   â”œâ”€â”€ data_querying.py            # SQL queries for reporting
â”‚   â”œâ”€â”€ live_data_processing.py     # Rolling metrics from live JSONL stream
â”‚   â””â”€â”€ data_modelling.py           # Create star schema: fact & dimension tables
â”‚__ live_ride_metrics.jsonl
â”œâ”€â”€ rides.db                   # SQLite database
â”œâ”€â”€ README.md
```

---

## ğŸš€ Features

- âœ… Mock batch and streaming data generation
- âœ… Batch ETL pipeline with cleaning rules
- âœ… SQLite-based storage and querying
- âœ… Star schema modeling with `fact_trips` and `dim_drivers`
- âœ… Real-time metrics via rolling window over live data
- âœ… All output stored as `.jsonl` or `.log` files

---

## ğŸ› ï¸ Setup Instructions

### 1. ğŸ“¦ Install dependencies

No external libraries beyond standard Python needed, except:

```bash
pip install pandas faker
```

---

## ğŸ“Š Data Generation

### Generate batch data (`rides.csv`)
```bash
python scripts/batch_data_generator.py
```

### Simulate live data stream (to `rides.jsonl`)
```bash
python scripts/live_data_gen.py
```

---

## ğŸ§¹ Batch ETL Pipeline

### Clean and load `rides.csv` into SQLite
```bash
python scripts/etl_batch.py
```

- Removes records with nulls or inconsistent times
- Adds ride duration column
- Loads into `fact_trips` table in `rides.db`

---

## ğŸ§± Data Modeling

### Create star schema tables
```bash
python scripts/data_modelling.py
```

Creates:
- `fact_trips`: fact table for trips
- `dim_drivers`: minimal driver dimension

---

## ğŸ“ˆ SQL-Based Reporting

### Query hourly trends, revenue, etc.
```bash
python scripts/data_querying.py
```

Outputs:
- `hourly_csv.log`: hourly trip counts
- Revenue per driver and other aggregations

---

## ğŸ“¡ Live Data Processing

### Read `rides.jsonl`, calculate rolling metrics
```bash
python scripts/live_data_processing.py
```

- Maintains rolling window of last 60 valid fares
- Calculates:
  - Trips per minute
  - Average fare
- Writes metrics to `live_ride_metrics.jsonl`

---

## ğŸ“ Sample Data Format

### rides.csv

| trip_id | driver_id | pickup_time | dropoff_time | pickup_location | fare_amount | status     |
|---------|-----------|-------------|--------------|------------------|-------------|------------|
| trip_1  | driver_3  | 2025-07-08 14:00 | 2025-07-08 14:30 | Delhi           | 35.5        | completed  |

### rides.jsonl (streaming format)

```json
{"trip_id": "trip_101", "fare_amount": 30.0, "pickup_time": "2025-07-09 12:45:01", ...}
```

---






 
